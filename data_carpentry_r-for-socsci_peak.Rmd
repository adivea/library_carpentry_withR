---
title: "data carpentry - r for socsci"
output: html_notebook
---

https://datacarpentry.org/r-socialsci/
https://github.com/datacarpentry/r-socialsci

```{r}
library(tidyverse)
library(fs)

```

## Get Data

Data are referenced at the top of the [data carpentry document](https://datacarpentry.org/r-socialsci/02-starting-with-data/index.html) that [links to a data description](https://datacarpentry.org/socialsci-workshop/data/) with [location information](https://figshare.com/articles/SAFI_Survey_Results/6262019)

Below, code chunk, conditionally downloads and emphatically imports the data.

```{r}
dir_create("data")

if(!file_exists("data/SAFI_clean.csv")) {
  download.file(
    "https://ndownloader.figshare.com/files/11492171",
    "data/SAFI_clean.csv")
}

interviews <- read_csv("data/SAFI_clean.csv", na = "NULL")
```


### Peak at the data

```{r}
glimpse(interviews)
interviews
```



DataCarpentry > R for SocSci > Starting with Data > Exercise

1. Create a data frame (interviews_100) containing only the data in row 100 of the surveys dataset.


```{r}
interviews_100 <- head(interviews, 100)
```

1. Notice how nrow() gave you the number of rows in a data frame?


     - Use that number to pull out just that last row in the data frame.
     - Compare that with what you see as the last row using tail() to make sure itâ€™s meeting expectations.
     - Pull out that last row using nrow() instead of the row number.
     - Create a new data frame (interviews_last) from that last row.
     
3. Use nrow() to extract the row that is in the middle of the data frame. Store the content of this row in an object named interviews_middle.

4. Combine nrow() with the - notation above to reproduce the behavior of head(interviews), keeping just the first through 6th rows of the interviews dataset.



## Factors

```{r}
respondent_floor_type <- factor(c("earth", "cement", "cement", "earth"))
```

```{r}
respondent_floor_type
```

```{r}
interviews_100 %>% 
  select(memb_assoc)
```


```{r}
ggplot(interviews, aes(x = memb_assoc)) +
  geom_bar()
```
```{r}
ggplot(interviews, 
       aes(x = fct_collapse(memb_assoc, 
                            No = "no",
                            Yes = "yes"))) +
  geom_bar()
```



```{r}
interviews %>% 
  mutate(memb_assoc = str_to_title(memb_assoc)) %>% 
  mutate(memb_assoc = if_else(is.na(memb_assoc),
                              "Undecided", 
                              memb_assoc)) %>% 
  ggplot(aes(memb_assoc)) + 
  geom_bar()
```

## dplyr & tidyr

subset the interviews data to include interviews where respondents were members of an irrigation association (memb_assoc) and retain only the columns affect_conflicts, liv_count, and no_meals.

### Select

```{r}
interviews %>% 
  filter(memb_assoc == "yes") %>% 
  select(affect_conflicts, liv_count, no_meals)
```

Right about now I'm thinking the [data science in a box](https://datasciencebox.org/) principles are pretty compelling. 
